{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ContestParcollet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ogb\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "Z3PcfMPLDOid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch_geometric\n",
        "import urllib3\n",
        "import outdated\n",
        "import torch\n",
        "\n",
        "!python -c \"import ogb; print(ogb.__version__)\"\n",
        "!python --version\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch_geometric.__version__)\n",
        "print(urllib3.__version__)\n",
        "print(outdated.__version__)\n",
        "\n",
        "!python3 -m pip show scikit-learn"
      ],
      "metadata": {
        "id": "QWltOysWDmUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG86cd7C1D6u"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# GCN model with 2 layers \n",
        "class GCN(torch.nn.Module):\n",
        "\n",
        "    # classes sorties, size des\n",
        "    def __init__(self, data, num_classes_end, hidden=128, layers_gcn=4):\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.num_layers_gcn = layers_gcn\n",
        "\n",
        "        # liste des couches de convolution\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        # liste des batch size normalisation\n",
        "        self.bns = torch.nn.ModuleList() \n",
        "\n",
        "        # ajout de la d'entrée \n",
        "        self.convs.append(GCNConv(data.num_node_features, hidden))   \n",
        "        # meilleur taux d'apprentissage et évite overfitting (change un peu les données d'entrées à chaque epoch) \n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden))\n",
        "\n",
        "        # profondeur du réseau (-2 car on enlève le début et la fin)\n",
        "        # on empile les couches cachés\n",
        "        for i in range(self.num_layers_gcn - 2):\n",
        "            self.convs.append(GCNConv(hidden, hidden))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden))\n",
        "\n",
        "        # couche de sortie\n",
        "        self.convs.append(GCNConv(hidden, num_classes_end))\n",
        "\n",
        "    # reset les paramètres entre les runs\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        # on récupère les features et la matrice d'adjacence\n",
        "        x, adj_t = data.x, data.adj_t\n",
        "\n",
        "        # on ajoute les couches de convolution\n",
        "        for i in range(self.num_layers_gcn - 1):\n",
        "            x = self.convs[i](x, adj_t)\n",
        "            x = self.bns[i](x) \n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # couche de sortie\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "\n",
        "        # sort un vecteur de probabilités désiquilibré\n",
        "        # log pour pas avoir des trop petites proba pour l'ordinateur\n",
        "        # ex 0.00000000001 = 0 pour la machine\n",
        "        x = F.log_softmax(x, dim=1)  \n",
        "        return x"
      ],
      "metadata": {
        "id": "_uW0xCxjhtS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, train_idx, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    # on récupère les prédictions\n",
        "    out = model(data)[train_idx]\n",
        "    # squeeze pour mettre en forme le y sous forme de vecteur\n",
        "    # nll loss permet de résoudre les porblème de classication avec c classe\n",
        "    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "TAtVGyv1IMQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 20\n",
        "hidden_channels = 128\n",
        "dropout = 0.5\n",
        "lr = 0.01\n",
        "epochs = 100\n",
        "runs = 5\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)\n",
        "\n",
        "dataset = PygNodePropPredDataset(name='ogbn-arxiv', transform=T.ToSparseTensor())"
      ],
      "metadata": {
        "id": "b6KPJQ44XznT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data\n",
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "# gets data\n",
        "data = dataset[0]\n",
        "data = data.to(device)\n",
        "\n",
        "# permet d'enlever l'orientation du graphe\n",
        "# car arxiv est grpahe orienté\n",
        "data.adj_t = data.adj_t.to_symmetric()\n",
        "\n",
        "# gets train features ids\n",
        "train_idx = split_idx['train'].to(device)\n",
        "\n",
        "# Create model\n",
        "model = GCN(data, dataset.num_classes).to(device)\n",
        "\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "metadata": {
        "id": "xSFe_ZfkYU4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_steps = 1\n",
        "\n",
        "best_acc_valid = []\n",
        "best_acc_test = []\n",
        "\n",
        "for i in range(runs):\n",
        "  best_test = 0\n",
        "  best_valid = 0\n",
        "  model.reset_parameters()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(1, 1 + epochs):\n",
        "    loss = train(model, data, train_idx, optimizer)\n",
        "    result = test(model, data, split_idx, evaluator)\n",
        "\n",
        "    if epoch % log_steps == 0:\n",
        "      train_acc, valid_acc, test_acc = result\n",
        "      print(f'Run: {i + 1:02d}, '\n",
        "            f'Epoch: {epoch:02d}, '\n",
        "            f'Loss: {loss:.4f}, '\n",
        "            f'Train: {100 * train_acc:.2f}%, '\n",
        "            f'Valid: {100 * valid_acc:.2f}%, '\n",
        "            f'Test: {100 * test_acc:.2f}%')\n",
        "                    \n",
        "    if test_acc > best_test:\n",
        "      best_test = test_acc\n",
        "    if valid_acc > best_valid:\n",
        "      best_valid = valid_acc\n",
        "\n",
        "  print(best_test, best_valid)\n",
        "  best_acc_valid.append(best_valid)\n",
        "  best_acc_test.append(best_test)\n",
        "\n",
        "\n",
        "moy_valid = sum(best_acc_valid) / len(best_acc_valid)\n",
        "moy_test = sum(best_acc_test) / len(best_acc_test)\n",
        "\n",
        "print(f'Validation {moy_valid} Test {moy_test}')"
      ],
      "metadata": {
        "id": "eOm9468Pc6XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "JKaFEHwrgNSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}